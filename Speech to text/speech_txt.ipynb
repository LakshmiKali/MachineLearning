{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: whisper in c:\\users\\lakie\\appdata\\roaming\\python\\python311\\site-packages (1.1.10)\n",
      "Requirement already satisfied: six in c:\\programdata\\miniconda3\\lib\\site-packages (from whisper) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\miniconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "! pip install whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(\"sample1.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" going along slushy country roads and speaking to damp audiences in drafty schoolrooms day after day for fortnight. He'll have to put in an appearance at some place of worship on Sunday morning, and he can come to us immediately afterwards.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def detect_language(text):\n",
    "    return detect(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     -- ------------------------------------ 61.4/981.5 kB 1.7 MB/s eta 0:00:01\n",
      "     ------ ------------------------------- 163.8/981.5 kB 2.0 MB/s eta 0:00:01\n",
      "     ----------- -------------------------- 286.7/981.5 kB 2.9 MB/s eta 0:00:01\n",
      "     -------------- ----------------------- 368.6/981.5 kB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 942.1/981.5 kB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 3.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\programdata\\miniconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993253 sha256=dc25ab6998e292ee6d42a2e0aab75faf78013bbefc9b41c3218f7a4b8ca3adfb\n",
      "  Stored in directory: c:\\users\\lakie\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\miniconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bb66cb95084dd08f724a1995edbd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lakie\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lakie\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-fr-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88dfaa87f524c279646c79ff80c0d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180a9717b027477390944fbf519da943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd3d35c3bd64ab2b7e4de5d702c458e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e79d17647714709affaecde6261a8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d059677d6854072ba0d48ace3dc7c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cff5a1c0a3435f910dd3be2ed57d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lakie\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text: Hello, everybody.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from langdetect import detect\n",
    "\n",
    "# Load the MarianMT model and tokenizer\n",
    "def load_model(source_lang):\n",
    "    model_name = f\"Helsinki-NLP/opus-mt-{source_lang}-en\"\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to translate text from any language to English\n",
    "def translate_to_english(text):\n",
    "    # Detect the language of the input text\n",
    "    source_language = detect(text)\n",
    "    model, tokenizer = load_model(source_language)\n",
    "    \n",
    "    # Prepare the input text\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate the translation\n",
    "    translated_ids = model.generate(input_ids, max_length=512, num_beams=4, early_stopping=True)\n",
    "    translated_text = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return translated_text\n",
    "\n",
    "# Example usage\n",
    "text = \"Bonjour tout le monde\"\n",
    "translated_text = translate_to_english(text)\n",
    "print(f\"Translated text: {translated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b159124d383f4b8690e791e070d4cf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lakie\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lakie\\.cache\\huggingface\\hub\\models--facebook--mbart-large-50-many-to-one-mmt. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261c57a1adfa458296a417002775deb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b05f63ba6c419085ca6798fceb9040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/268 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d04d6a736f45629758f6a2171d385d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26639a5aa1ec4e3094e20da7776a5827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9805fecba5ce42c3ab3588afa047af43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text: Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good All All All All All All All All All All All All All All All All All Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good Good All All All All All All All All All All All All All All All All All All All All All All All All All All All All All\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "from langdetect import detect\n",
    "\n",
    "# Load the mBART model and tokenizer\n",
    "model_name = \"facebook/mbart-large-50-many-to-one-mmt\"\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "# Function to translate text from any language to English\n",
    "def translate_to_english(text):\n",
    "    # Detect the language of the input text\n",
    "    source_language = detect(text)\n",
    "    tokenizer.src_lang = source_language\n",
    "    \n",
    "    # Prepare the input text\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    # Generate the translation\n",
    "    generated_ids = model.generate(input_ids, max_length=512, num_beams=4, early_stopping=True)\n",
    "    translated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return translated_text\n",
    "\n",
    "# Example usage\n",
    "text = \"Bonjour tout le monde\"\n",
    "translated_text = translate_to_english(text)\n",
    "print(f\"Translated text: {translated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "Translated text: Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer Mer\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"Merheba\"\n",
    "print(detect_language(text))\n",
    "translated_text = translate_to_english(text)\n",
    "print(f\"Translated text: {translated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
